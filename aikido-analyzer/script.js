/**
 * ü•ã MESTRE HIKARI - AN√ÅLISE DE MOVIMENTO
 * MediaPipe Pose + GPT-4 Vision + ElevenLabs
 */

// ========================================
// VARI√ÅVEIS GLOBAIS
// ========================================

let pose;
let camera;
let currentStream;
let isAnalyzing = false;
let lastPoseData = null;
let facingMode = 'environment'; // 'user' (frontal) ou 'environment' (traseira) - FIXO EM TRASEIRA

// Elementos DOM
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const canvasCtx = canvas.getContext('2d');
const statusDiv = document.getElementById('status');
const analyzeBtn = document.getElementById('analyze-btn');
// const toggleCameraBtn = document.getElementById('toggle-camera'); // Removido - c√¢mera fixa
const techniqueSelect = document.getElementById('technique');
const feedbackArea = document.getElementById('feedback-area');
const feedbackText = document.getElementById('feedback-text');
const landmarksInfo = document.getElementById('landmarks-info');
const audioPlayer = document.getElementById('audio-player');
const playAudioBtn = document.getElementById('play-audio-btn');

// Debug Panel
const debugPanel = document.getElementById('debug-panel');
const debugLogs = document.getElementById('debug-logs');
const debugToggleBtn = document.getElementById('debug-toggle');
const debugCopyBtn = document.getElementById('debug-copy');

// ========================================
// SISTEMA DE DEBUG (Mobile)
// ========================================

function debugLog(message, type = 'info') {
    /**
     * Adiciona log ao painel de debug na tela
     * Tipos: 'info', 'warn', 'error'
     */
    const time = new Date().toLocaleTimeString();
    const entry = document.createElement('div');
    entry.className = `debug-log-entry ${type}`;
    entry.innerHTML = `<span class="debug-log-time">${time}</span>${message}`;
    
    debugLogs.appendChild(entry);
    debugLogs.scrollTop = debugLogs.scrollHeight;
    
    // Manter no console tamb√©m
    console.log(`[${type.toUpperCase()}] ${message}`);
    
    // Limitar a 50 entradas
    while (debugLogs.children.length > 50) {
        debugLogs.removeChild(debugLogs.firstChild);
    }
}

// Toggle minimizar/expandir
debugToggleBtn.addEventListener('click', () => {
    debugPanel.classList.toggle('minimized');
    debugToggleBtn.textContent = debugPanel.classList.contains('minimized') ? '+' : '‚àí';
});

// Copiar logs
debugCopyBtn.addEventListener('click', () => {
    const allLogs = Array.from(debugLogs.children)
        .map(entry => entry.textContent)
        .join('\n');
    
    navigator.clipboard.writeText(allLogs).then(() => {
        debugLog('‚úÖ Logs copiados para clipboard!', 'info');
        setTimeout(() => {
            debugCopyBtn.textContent = '‚úì';
            setTimeout(() => {
                debugCopyBtn.textContent = 'üìã';
            }, 1000);
        }, 100);
    }).catch(err => {
        debugLog('‚ùå Erro ao copiar: ' + err.message, 'error');
    });
});

// ========================================
// INICIALIZA√á√ÉO
// ========================================

window.addEventListener('load', async () => {
    debugLog('ü•ã Mestre Hikari - An√°lise de Movimento inicializado', 'info');
    console.log('ü•ã Mestre Hikari - An√°lise de Movimento inicializado');
    
    if (CONFIG.DEBUG) {
        debugLog('üîß Modo DEBUG ativo', 'info');
        console.log('üîß Modo DEBUG ativo');
        console.log('üìä Configura√ß√µes:', CONFIG);
    }
    
    debugLog(`üéØ FacingMode configurado: "${facingMode}"`, 'info');
    debugLog('üì± Modelo: ' + (navigator.userAgent.match(/Android|iPhone|iPad/i) || ['Desktop'])[0], 'info');
    
    await initMediaPipe();
    await initCamera();
});

// ========================================
// MEDIAPIPE SETUP
// ========================================

async function initMediaPipe() {
    debugLog('ü§ñ Carregando MediaPipe Pose...', 'info');
    statusDiv.textContent = 'Carregando MediaPipe...';
    
    pose = new Pose({
        locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`;
        }
    });
    
    pose.setOptions({
        modelComplexity: 1,
        smoothLandmarks: true,
        enableSegmentation: false,
        smoothSegmentation: false,
        minDetectionConfidence: CONFIG.ANALYSIS.minPoseConfidence,
        minTrackingConfidence: CONFIG.ANALYSIS.minPoseConfidence
    });
    
    pose.onResults(onPoseResults);
    
    debugLog('‚úÖ MediaPipe Pose carregado', 'info');
    console.log('‚úÖ MediaPipe Pose carregado');
}

// ========================================
// C√ÇMERA SETUP
// ========================================

async function getBackCameraDeviceId(existingStream) {
    /**
     * Enumera c√¢meras e retorna o deviceId da traseira
     * @param {MediaStream} existingStream - Stream j√° existente para extrair deviceId
     * Retorna null se n√£o encontrar
     */
    try {
        debugLog('üîç Enumerando c√¢meras dispon√≠veis...', 'info');
        const devices = await navigator.mediaDevices.enumerateDevices();
        const videoDevices = devices.filter(device => device.kind === 'videoinput');
        
        debugLog(`üìπ Encontradas ${videoDevices.length} c√¢meras`, 'info');
        
        // Se j√° temos um stream ativo, extrair deviceId dele
        if (existingStream) {
            const existingTrack = existingStream.getVideoTracks()[0];
            const existingSettings = existingTrack.getSettings();
            const existingDeviceId = existingSettings.deviceId;
            
            debugLog(`üîé Stream atual: "${existingTrack.label}"`, 'info');
            debugLog(`üîé DeviceId atual: ${existingDeviceId ? existingDeviceId.substring(0, 20) + '...' : 'N/A'}`, 'info');
            
            if (existingSettings.facingMode === 'environment') {
                debugLog(`‚úÖ Stream atual J√Å √â traseira! Usando deviceId dele.`, 'info');
                return existingDeviceId;
            }
        }
        
        // Procurar c√¢mera traseira por label (agora que temos permiss√£o, labels aparecem)
        debugLog('üîç Procurando c√¢mera traseira por label...', 'info');
        const backKeywords = ['back', 'rear', 'traseira', 'tr√°s', 'tripla traseira', 'triple'];
        
        for (const device of videoDevices) {
            const label = device.label.toLowerCase();
            debugLog(`  - "${device.label}" (ID: ${device.deviceId.substring(0, 20)}...)`, 'info');
            
            if (backKeywords.some(keyword => label.includes(keyword))) {
                debugLog(`‚úÖ C√¢mera traseira encontrada por label: "${device.label}"`, 'info');
                return device.deviceId;
            }
        }
        
        // Fallback: tentar pegar settings de cada c√¢mera
        debugLog('üîÑ Fallback: testando facingMode de cada c√¢mera...', 'info');
        for (const device of videoDevices) {
            try {
                const tempStream = await navigator.mediaDevices.getUserMedia({
                    video: { deviceId: { exact: device.deviceId } }
                });
                
                const track = tempStream.getVideoTracks()[0];
                const settings = track.getSettings();
                
                debugLog(`    "${device.label}" ‚Üí FacingMode: ${settings.facingMode || 'N/A'}`, 'info');
                
                // Parar stream tempor√°rio
                track.stop();
                
                // Se for environment, retornar este deviceId
                if (settings.facingMode === 'environment') {
                    debugLog(`‚úÖ C√¢mera traseira encontrada por facingMode: "${device.label}"`, 'info');
                    return device.deviceId;
                }
            } catch (err) {
                debugLog(`    ‚ö†Ô∏è Erro ao testar: ${err.message}`, 'warn');
            }
        }
        
        debugLog('‚ö†Ô∏è C√¢mera traseira n√£o encontrada. Usando padr√£o.', 'warn');
        return null;
        
    } catch (error) {
        debugLog(`‚ùå Erro ao enumerar c√¢meras: ${error.message}`, 'error');
        return null;
    }
}

async function initCamera() {
    try {
        debugLog('üé• Iniciando c√¢mera...', 'info');
        statusDiv.textContent = 'Solicitando acesso √† c√¢mera...';
        
        // ETAPA 1: Pedir permiss√£o inicial com facingMode (para desbloquear labels)
        debugLog('1Ô∏è‚É£ Pedindo permiss√£o inicial com facingMode...', 'info');
        const initialConstraints = {
            video: {
                facingMode: facingMode,
                width: { ideal: 1280 },
                height: { ideal: 720 }
            }
        };
        
        let initialStream = await navigator.mediaDevices.getUserMedia(initialConstraints);
        const initialTrack = initialStream.getVideoTracks()[0];
        const initialSettings = initialTrack.getSettings();
        
        debugLog(`‚úÖ Permiss√£o concedida!`, 'info');
        debugLog(`üìπ Stream inicial: "${initialTrack.label}"`, 'info');
        debugLog(`üëÅÔ∏è FacingMode: ${initialSettings.facingMode || 'N/A'}`, 'info');
        
        // ETAPA 2: Agora enumerar c√¢meras (labels dispon√≠veis ap√≥s permiss√£o)
        debugLog('2Ô∏è‚É£ Enumerando c√¢meras (labels agora dispon√≠veis)...', 'info');
        const backCameraId = await getBackCameraDeviceId(initialStream);
        
        let finalStream;
        let constraints;
        
        if (backCameraId && backCameraId !== initialSettings.deviceId) {
            // ETAPA 3: Recriar stream com deviceId LOCKED
            debugLog('3Ô∏è‚É£ Recriando stream com deviceId LOCKED...', 'info');
            
            // Parar stream inicial
            initialTrack.stop();
            
            // Criar novo stream com deviceId espec√≠fico
            constraints = {
                video: {
                    deviceId: { exact: backCameraId },
                    width: { ideal: 1280 },
                    height: { ideal: 720 }
                }
            };
            
            debugLog(`üìã Usando deviceId espec√≠fico: ${backCameraId.substring(0, 20)}...`, 'info');
            finalStream = await navigator.mediaDevices.getUserMedia(constraints);
            
        } else if (backCameraId && backCameraId === initialSettings.deviceId) {
            // Stream inicial j√° √© o correto!
            debugLog('3Ô∏è‚É£ Stream inicial j√° √© a c√¢mera traseira! Mantendo...', 'info');
            finalStream = initialStream;
            
        } else {
            // Fallback: manter stream inicial (n√£o conseguimos identificar traseira)
            debugLog('3Ô∏è‚É£ N√£o identificou traseira. Usando stream inicial.', 'warn');
            finalStream = initialStream;
        }
        
        currentStream = finalStream;
        
        // Analisar stream final
        const videoTrack = currentStream.getVideoTracks()[0];
        const settings = videoTrack.getSettings();
        const capabilities = videoTrack.getCapabilities ? videoTrack.getCapabilities() : {};
        
        debugLog(`‚úÖ Stream final definido!`, 'info');
        debugLog(`üìπ Track label: "${videoTrack.label}"`, 'info');
        debugLog(`üÜî DeviceId: ${settings.deviceId ? settings.deviceId.substring(0, 20) + '...' : 'N/A'}`, 'info');
        debugLog(`üëÅÔ∏è FacingMode: ${settings.facingMode || 'N/A'}`, 'info');
        debugLog(`üìê Resolu√ß√£o: ${settings.width}x${settings.height}`, 'info');
        
        if (backCameraId) {
            debugLog(`üîí DeviceId LOCKED (MediaPipe n√£o pode trocar!)`, 'info');
        } else {
            debugLog(`‚ö†Ô∏è DeviceId n√£o foi locked (MediaPipe pode sobrescrever)`, 'warn');
        }
        
        // 4Ô∏è‚É£ SETAR VIDEO.SRCOBJECT
        debugLog('4Ô∏è‚É£ Setando video.srcObject...', 'info');
        video.srcObject = currentStream;
        
        video.addEventListener('loadeddata', async () => {
            debugLog('5Ô∏è‚É£ V√≠deo carregado (loadeddata)', 'info');
            
            // Verificar se o stream ainda √© o mesmo
            const currentVideoTrack = video.srcObject.getVideoTracks()[0];
            const currentSettings = currentVideoTrack.getSettings();
            debugLog(`üìπ Stream ativo: "${currentVideoTrack.label}"`, 'info');
            debugLog(`üëÅÔ∏è FacingMode atual: ${currentSettings.facingMode || 'N/A'}`, 'info');
            
            // Definir dimens√µes fixas do canvas (evita redimensionamento)
            const containerWidth = video.parentElement.offsetWidth;
            const containerHeight = video.parentElement.offsetHeight;
            
            canvas.width = containerWidth;
            canvas.height = containerHeight;
            
            debugLog(`üìê Canvas: ${canvas.width}x${canvas.height}`, 'info');
            
            // 6Ô∏è‚É£ CRIAR MEDIAPIPE CAMERA
            debugLog('6Ô∏è‚É£ Criando MediaPipe Camera...', 'info');
            camera = new Camera(video, {
                onFrame: async () => {
                    await pose.send({ image: video });
                },
                width: 1280,
                height: 720
            });
            
            debugLog('‚úÖ MediaPipe Camera criado', 'info');
            
            // 7Ô∏è‚É£ INICIAR MEDIAPIPE CAMERA
            debugLog('7Ô∏è‚É£ Iniciando camera.start()...', 'info');
            camera.start();
            
            // Aguardar um pouco e verificar novamente
            setTimeout(() => {
                const finalVideoTrack = video.srcObject.getVideoTracks()[0];
                const finalSettings = finalVideoTrack.getSettings();
                const initialDeviceId = settings.deviceId;
                
                debugLog('8Ô∏è‚É£ VERIFICA√á√ÉO FINAL:', 'info');
                debugLog(`üìπ Track final: "${finalVideoTrack.label}"`, 'info');
                debugLog(`üëÅÔ∏è FacingMode final: ${finalSettings.facingMode || 'N/A'}`, 'info');
                debugLog(`üÜî DeviceId final: ${finalSettings.deviceId ? finalSettings.deviceId.substring(0, 20) + '...' : 'N/A'}`, 'info');
                
                // Verificar se o deviceId mudou (mais confi√°vel que facingMode)
                if (initialDeviceId && finalSettings.deviceId !== initialDeviceId) {
                    debugLog(`üî¥ PROBLEMA! DeviceId mudou!`, 'error');
                    debugLog(`üî¥ Inicial: ${initialDeviceId.substring(0, 20)}...`, 'error');
                    debugLog(`üî¥ Final: ${finalSettings.deviceId.substring(0, 20)}...`, 'error');
                } else if (finalSettings.facingMode === 'environment' || finalSettings.facingMode === facingMode) {
                    debugLog(`‚úÖ‚úÖ SUCESSO! C√¢mera traseira mantida!`, 'info');
                    debugLog(`‚úÖ‚úÖ A corre√ß√£o funcionou!`, 'info');
                } else {
                    debugLog(`‚ö†Ô∏è FacingMode: ${finalSettings.facingMode} (esperado: ${facingMode})`, 'warn');
                }
            }, 1000);
            
            statusDiv.textContent = 'C√¢mera ativa - Posicione-se';
            statusDiv.classList.add('detecting');
            analyzeBtn.disabled = false;
            
            debugLog('‚úÖ C√¢mera totalmente inicializada', 'info');
        }, { once: true }); // Garante que s√≥ execute uma vez
        
    } catch (error) {
        debugLog(`‚ùå ERRO ao acessar c√¢mera: ${error.message}`, 'error');
        console.error('‚ùå Erro ao acessar c√¢mera:', error);
        statusDiv.textContent = 'Erro: Permita o acesso √† c√¢mera';
        statusDiv.style.background = 'rgba(239, 68, 68, 0.8)';
    }
}

// ========================================
// CALLBACK DO MEDIAPIPE
// ========================================

function onPoseResults(results) {
    // Otimiza√ß√£o: s√≥ desenhar se o canvas existir e tiver dimens√µes
    if (!canvas.width || !canvas.height) return;
    
    // Limpar canvas (sem piscar)
    canvasCtx.save();
    canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
    
    // Desenhar landmarks se detectado
    if (results.poseLandmarks) {
        lastPoseData = results;
        
        // Desenhar conex√µes
        drawConnectors(canvasCtx, results.poseLandmarks, POSE_CONNECTIONS, {
            color: '#667eea',
            lineWidth: 4
        });
        
        // Desenhar pontos
        drawLandmarks(canvasCtx, results.poseLandmarks, {
            color: '#ffffff',
            fillColor: '#667eea',
            lineWidth: 2,
            radius: 6
        });
        
        // Debug: mostrar pontos principais (s√≥ quando n√£o est√° analisando)
        if (CONFIG.DEBUG && !isAnalyzing) {
            drawDebugInfo(results.poseLandmarks);
        }
    }
    
    canvasCtx.restore();
}

// ========================================
// DESENHAR INFO DE DEBUG
// ========================================

function drawDebugInfo(landmarks) {
    const keyPoints = [
        { idx: 11, name: 'Ombro Esq.' },
        { idx: 12, name: 'Ombro Dir.' },
        { idx: 13, name: 'Cotovelo Esq.' },
        { idx: 14, name: 'Cotovelo Dir.' },
        { idx: 23, name: 'Quadril Esq.' },
        { idx: 24, name: 'Quadril Dir.' }
    ];
    
    canvasCtx.font = '12px monospace';
    canvasCtx.fillStyle = '#10b981';
    
    keyPoints.forEach(point => {
        const landmark = landmarks[point.idx];
        if (landmark) {
            const x = landmark.x * canvas.width;
            const y = landmark.y * canvas.height;
            canvasCtx.fillText(point.name, x + 10, y);
        }
    });
}

// ========================================
// CALCULAR √ÇNGULOS E ALINHAMENTOS
// ========================================

function calculatePoseMetrics(landmarks) {
    /**
     * Calcula m√©tricas importantes para an√°lise de Aikid√¥:
     * - √Çngulos de cotovelos, ombros, joelhos
     * - Alinhamento ombro-quadril
     * - Centro de gravidade
     * - Dist√¢ncias relativas
     */
    
    const metrics = {
        angles: {},
        alignments: {},
        center: {},
        distances: {}
    };
    
    // Landmarks importantes (√≠ndices do MediaPipe)
    const LEFT_SHOULDER = 11;
    const RIGHT_SHOULDER = 12;
    const LEFT_ELBOW = 13;
    const RIGHT_ELBOW = 14;
    const LEFT_WRIST = 15;
    const RIGHT_WRIST = 16;
    const LEFT_HIP = 23;
    const RIGHT_HIP = 24;
    const LEFT_KNEE = 25;
    const RIGHT_KNEE = 26;
    const LEFT_ANKLE = 27;
    const RIGHT_ANKLE = 28;
    
    // Calcular √¢ngulo do cotovelo direito
    metrics.angles.rightElbow = calculateAngle(
        landmarks[RIGHT_SHOULDER],
        landmarks[RIGHT_ELBOW],
        landmarks[RIGHT_WRIST]
    );
    
    // Calcular √¢ngulo do cotovelo esquerdo
    metrics.angles.leftElbow = calculateAngle(
        landmarks[LEFT_SHOULDER],
        landmarks[LEFT_ELBOW],
        landmarks[LEFT_WRIST]
    );
    
    // Calcular √¢ngulo do ombro direito (em rela√ß√£o ao quadril)
    metrics.angles.rightShoulder = calculateAngle(
        landmarks[RIGHT_ELBOW],
        landmarks[RIGHT_SHOULDER],
        landmarks[RIGHT_HIP]
    );
    
    // Calcular √¢ngulo do ombro esquerdo
    metrics.angles.leftShoulder = calculateAngle(
        landmarks[LEFT_ELBOW],
        landmarks[LEFT_SHOULDER],
        landmarks[LEFT_HIP]
    );
    
    // Calcular alinhamento ombro-quadril (porcentagem)
    const shoulderMid = {
        x: (landmarks[LEFT_SHOULDER].x + landmarks[RIGHT_SHOULDER].x) / 2,
        y: (landmarks[LEFT_SHOULDER].y + landmarks[RIGHT_SHOULDER].y) / 2
    };
    
    const hipMid = {
        x: (landmarks[LEFT_HIP].x + landmarks[RIGHT_HIP].x) / 2,
        y: (landmarks[LEFT_HIP].y + landmarks[RIGHT_HIP].y) / 2
    };
    
    metrics.alignments.shoulderHipAlignment = Math.abs(shoulderMid.x - hipMid.x) * 100;
    
    // Centro de gravidade (simplificado)
    metrics.center.x = hipMid.x;
    metrics.center.y = hipMid.y;
    metrics.center.deviation = Math.abs(0.5 - hipMid.x) * 100; // desvio do centro (%)
    
    // Dist√¢ncia entre p√©s (base)
    metrics.distances.footDistance = calculateDistance(
        landmarks[LEFT_ANKLE],
        landmarks[RIGHT_ANKLE]
    ) * 100;
    
    // Altura da postura (joelho ao ombro)
    metrics.distances.postureHeight = Math.abs(
        ((landmarks[LEFT_KNEE].y + landmarks[RIGHT_KNEE].y) / 2) -
        ((landmarks[LEFT_SHOULDER].y + landmarks[RIGHT_SHOULDER].y) / 2)
    ) * 100;
    
    return metrics;
}

function calculateAngle(a, b, c) {
    /**
     * Calcula √¢ngulo entre 3 pontos (em graus)
     * b √© o v√©rtice do √¢ngulo
     */
    const radians = Math.atan2(c.y - b.y, c.x - b.x) - 
                    Math.atan2(a.y - b.y, a.x - b.x);
    let angle = Math.abs(radians * 180.0 / Math.PI);
    
    if (angle > 180.0) {
        angle = 360 - angle;
    }
    
    return Math.round(angle);
}

function calculateDistance(a, b) {
    /**
     * Calcula dist√¢ncia euclidiana entre 2 pontos
     */
    return Math.sqrt(Math.pow(b.x - a.x, 2) + Math.pow(b.y - a.y, 2));
}

function interpretMetrics(metrics) {
    /**
     * Converte m√©tricas num√©ricas em descri√ß√µes qualitativas
     * para inclus√£o no prompt (GPT n√£o menciona n√∫meros na resposta)
     */
    const interpretations = [];
    
    // Cotovelos
    if (metrics.angles.rightElbow < 90) {
        interpretations.push('- Cotovelo direito muito dobrado (fechado)');
    } else if (metrics.angles.rightElbow > 160) {
        interpretations.push('- Cotovelo direito muito estendido (travado)');
    } else if (metrics.angles.rightElbow >= 120 && metrics.angles.rightElbow <= 150) {
        interpretations.push('- Cotovelo direito em boa posi√ß√£o');
    }
    
    if (metrics.angles.leftElbow < 90) {
        interpretations.push('- Cotovelo esquerdo muito dobrado (fechado)');
    } else if (metrics.angles.leftElbow > 160) {
        interpretations.push('- Cotovelo esquerdo muito estendido (travado)');
    } else if (metrics.angles.leftElbow >= 120 && metrics.angles.leftElbow <= 150) {
        interpretations.push('- Cotovelo esquerdo em boa posi√ß√£o');
    }
    
    // Alinhamento ombro-quadril
    if (metrics.alignments.shoulderHipAlignment > 5) {
        interpretations.push('- Ombros desalinhados com quadris (corpo torcido)');
    } else if (metrics.alignments.shoulderHipAlignment < 2) {
        interpretations.push('- Ombros bem alinhados com quadris');
    }
    
    // Centro
    if (metrics.center.deviation > 8) {
        const direction = metrics.center.x > 0.5 ? 'direita' : 'esquerda';
        interpretations.push(`- Centro de gravidade deslocado para a ${direction}`);
    } else if (metrics.center.deviation < 3) {
        interpretations.push('- Centro de gravidade bem posicionado');
    }
    
    // Base (dist√¢ncia entre p√©s)
    if (metrics.distances.footDistance < 15) {
        interpretations.push('- Base estreita (p√©s muito juntos)');
    } else if (metrics.distances.footDistance > 35) {
        interpretations.push('- Base muito ampla (p√©s muito afastados)');
    } else if (metrics.distances.footDistance >= 20 && metrics.distances.footDistance <= 30) {
        interpretations.push('- Base adequada para estabilidade');
    }
    
    // Altura da postura
    if (metrics.distances.postureHeight > 45) {
        interpretations.push('- Postura alta (centro pode estar elevado demais)');
    } else if (metrics.distances.postureHeight < 35) {
        interpretations.push('- Postura muito baixa (pode comprometer mobilidade)');
    } else {
        interpretations.push('- Altura da postura adequada');
    }
    
    return interpretations;
}

function assessTechniqueQuality(interpretations) {
    /**
     * Avalia a qualidade geral com base nas interpreta√ß√µes
     * Retorna: "Boa execu√ß√£o", "Precisa ajustes", "Execu√ß√£o adequada com pequenos ajustes"
     */
    const positiveKeywords = ['bem', 'boa', 'adequada', 'correto'];
    const negativeKeywords = ['muito', 'demais', 'deslocado', 'estreita', 'alta', 'baixa', 'travado', 'dobrado', 'torcido'];
    
    let goodCount = 0;
    let badCount = 0;
    
    interpretations.forEach(interp => {
        const lower = interp.toLowerCase();
        if (positiveKeywords.some(kw => lower.includes(kw))) {
            goodCount++;
        }
        if (negativeKeywords.some(kw => lower.includes(kw))) {
            badCount++;
        }
    });
    
    if (badCount === 0 && goodCount > 0) {
        return "‚úÖ T√©cnica bem executada - elogie o praticante!";
    } else if (badCount > goodCount) {
        return "‚ö†Ô∏è T√©cnica precisa de ajustes - corrija com compaix√£o.";
    } else {
        return "üü° T√©cnica parcialmente correta - elogie o que est√° bom e corrija o necess√°rio.";
    }
}

// ========================================
// CAPTURAR FRAME COMO BASE64
// ========================================

function captureFrame() {
    const tempCanvas = document.createElement('canvas');
    tempCanvas.width = video.videoWidth;
    tempCanvas.height = video.videoHeight;
    const tempCtx = tempCanvas.getContext('2d');
    
    tempCtx.drawImage(video, 0, 0);
    
    return tempCanvas.toDataURL('image/jpeg', CONFIG.ANALYSIS.imageQuality).split(',')[1];
}

// ========================================
// ANALISAR COM GPT-4 VISION
// ========================================

async function analyzeMovement() {
    if (!lastPoseData || !lastPoseData.poseLandmarks) {
        alert('‚ö†Ô∏è Nenhuma pose detectada. Posicione-se na frente da c√¢mera.');
        return;
    }
    
    if (isAnalyzing) {
        return;
    }
    
    isAnalyzing = true;
    analyzeBtn.disabled = true;
    feedbackArea.classList.add('hidden');
    
    try {
        // COUNTDOWN: Dar tempo para o aluno se posicionar
        await performCountdown();
        
        const technique = techniqueSelect.value;
        let images = [];
        let metricsSequence = [];
        
        if (CONFIG.ANALYSIS.captureSequence) {
            // MODO SEQU√äNCIA: Captura m√∫ltiplos frames durante o movimento
            const capturedData = await captureMovementSequence();
            images = capturedData.images;
            metricsSequence = capturedData.metrics;
            
            if (CONFIG.DEBUG) {
                console.log(`üì∏ Capturados ${images.length} frames do movimento`);
                console.log('üìä Sequ√™ncia de m√©tricas:', metricsSequence);
            }
        } else {
            // MODO FOTO √öNICA (antigo)
            const imageBase64 = CONFIG.ANALYSIS.includeImage ? captureFrame() : null;
            if (imageBase64) images.push(imageBase64);
            metricsSequence.push(calculatePoseMetrics(lastPoseData.poseLandmarks));
        }
        
        // Analisando...
        statusDiv.textContent = 'Analisando movimento...';
        statusDiv.classList.remove('detecting');
        statusDiv.classList.add('analyzing');
        
        // Usar m√©tricas m√©dias ou da √∫ltima captura
        const finalMetrics = metricsSequence[metricsSequence.length - 1];
        
        // Criar prompt
        const prompt = createAnalysisPrompt(technique, finalMetrics, images.length);
        
        if (CONFIG.DEBUG) {
            console.log('üìù Prompt:', prompt);
        }
        
        // Chamar GPT-4 Vision
        const analysis = await callGPT4Vision(prompt, images);
        
        // Exibir feedback
        displayFeedback(analysis, finalMetrics);
        
        // Gerar √°udio (ElevenLabs)
        await generateAndPlayAudio(analysis);
        
    } catch (error) {
        console.error('‚ùå Erro na an√°lise:', error);
        alert('Erro ao analisar movimento: ' + error.message);
        statusDiv.textContent = 'Erro na an√°lise';
        statusDiv.style.background = 'rgba(239, 68, 68, 0.8)';
    } finally {
        isAnalyzing = false;
        analyzeBtn.disabled = false;
        statusDiv.textContent = 'An√°lise conclu√≠da';
        statusDiv.classList.remove('analyzing');
        statusDiv.classList.add('detecting');
    }
}

async function performCountdown() {
    /**
     * Countdown de 3 segundos para dar tempo do aluno se posicionar
     */
    const countdownDuration = 3;
    
    for (let i = countdownDuration; i > 0; i--) {
        statusDiv.textContent = `Prepare-se... ${i}`;
        statusDiv.classList.remove('detecting', 'analyzing');
        statusDiv.classList.add('analyzing');
        await new Promise(resolve => setTimeout(resolve, 1000));
    }
    
    // Sinalizar in√≠cio da captura
    if (CONFIG.ANALYSIS.captureSequence) {
        statusDiv.textContent = `üé• Executando movimento... (${CONFIG.ANALYSIS.sequenceDuration}s)`;
    } else {
        statusDiv.textContent = 'üì∏ Capturando!';
    }
    
    canvas.style.border = '5px solid #10b981';
    await new Promise(resolve => setTimeout(resolve, 300));
    canvas.style.border = 'none';
}

async function captureMovementSequence() {
    /**
     * Captura uma sequ√™ncia de frames durante o movimento
     * Retorna: { images: [...], metrics: [...] }
     */
    const duration = CONFIG.ANALYSIS.sequenceDuration * 1000; // converter para ms
    const fps = CONFIG.ANALYSIS.framesPerSecond;
    const interval = 1000 / fps; // intervalo entre capturas em ms
    const totalFrames = Math.floor(duration / interval);
    
    const images = [];
    const metrics = [];
    
    let frameCount = 0;
    const startTime = Date.now();
    
    return new Promise((resolve) => {
        const captureInterval = setInterval(() => {
            frameCount++;
            const elapsed = Date.now() - startTime;
            const remaining = Math.ceil((duration - elapsed) / 1000);
            
            // Atualizar status com tempo restante
            if (remaining > 0) {
                statusDiv.textContent = `üé• Gravando movimento... ${remaining}s`;
            }
            
            // Efeito visual de grava√ß√£o (pisca suave)
            if (frameCount % 2 === 0) {
                canvas.style.border = '3px solid #ef4444';
                setTimeout(() => canvas.style.border = 'none', 100);
            }
            
            // Capturar frame e m√©tricas
            if (lastPoseData && lastPoseData.poseLandmarks) {
                try {
                    const frame = captureFrame();
                    const frameMetrics = calculatePoseMetrics(lastPoseData.poseLandmarks);
                    images.push(frame);
                    metrics.push(frameMetrics);
                } catch (err) {
                    console.warn('Erro ao capturar frame:', err);
                }
            }
            
            // Verificar se terminou
            if (elapsed >= duration || frameCount >= totalFrames) {
                clearInterval(captureInterval);
                canvas.style.border = 'none';
                statusDiv.textContent = '‚úÖ Grava√ß√£o conclu√≠da!';
                
                if (CONFIG.DEBUG) {
                    console.log(`‚úÖ Capturados ${images.length} frames em ${(elapsed/1000).toFixed(1)}s`);
                }
                
                resolve({ images, metrics });
            }
        }, interval);
    });
}

// ========================================
// CRIAR PROMPT PARA GPT-4
// ========================================

function createAnalysisPrompt(technique, metrics, frameCount = 1) {
    const techniques = {
        'ikkyo': {
            name: 'Ikkyo (Primeiro Princ√≠pio)',
            focus: 'Controle do cotovelo junto ao centro, alinhamento do corpo, peso baixo e condu√ß√£o com o corpo inteiro.'
        },
        'shiho-nage': {
            name: 'Shiho-nage (Proje√ß√£o nas 4 Dire√ß√µes)',
            focus: 'Eleva√ß√£o do bra√ßo acima da cabe√ßa, trazer o uke para o centro, giro do corpo em bloco, movimento pr√≥ximo como corte de espada.'
        },
        'irimi-nage': {
            name: 'Irimi-nage (Entrar e Projetar)',
            focus: 'Entrada no ponto cego (irimi verdadeiro), passar atr√°s da linha, controle da cabe√ßa/linha, proje√ß√£o descendo o peso.'
        },
        'kokyu-ho': {
            name: 'Kokyu-ho (Exerc√≠cio de Respira√ß√£o)',
            focus: 'Estabilidade no seiza, uso do centro e respira√ß√£o, n√£o empurrar com ombros, acompanhar o parceiro at√© o fim.'
        }
    };
    
    const selectedTechnique = techniques[technique];
    
    // Interpreta√ß√µes qualitativas dos dados (para o prompt)
    const interpretations = interpretMetrics(metrics);
    
    // Avaliar qualidade geral da t√©cnica
    const qualityAssessment = assessTechniqueQuality(interpretations);
    
    const sequenceInfo = frameCount > 1 
        ? `**${frameCount} imagens em sequ√™ncia do movimento foram anexadas. Analise o FLUXO COMPLETO da t√©cnica, do in√≠cio ao fim.**`
        : CONFIG.ANALYSIS.includeImage ? '**Uma imagem do movimento est√° anexada para an√°lise visual complementar.**' : '';
    
    return `Voc√™ √© o Mestre Hikari, um sensei experiente de Aikid√¥. Analise o movimento do praticante que est√° executando a t√©cnica **${selectedTechnique.name}**.

**Foco da T√©cnica:**
${selectedTechnique.focus}

**Observa√ß√µes Biomec√¢nicas (√∫ltima captura):**
${interpretations.join('\n')}

**Avalia√ß√£o Geral:**
${qualityAssessment}

${sequenceInfo}

**Instru√ß√µes Cr√≠ticas (COMO UM SENSEI VERDADEIRO):**
${frameCount > 1 ? '0. Voc√™ recebeu M√öLTIPLAS IMAGENS em sequ√™ncia. Analise o MOVIMENTO COMPLETO, n√£o apenas uma pose. Observe a transi√ß√£o, o fluxo, a continuidade da t√©cnica do in√≠cio ao fim.\n' : ''}
1. Se a t√©cnica est√° **CORRETA/BOA**: ELOGIE primeiro! Reconhe√ßa o que est√° bem feito. Use frases como:
   - "Excelente! Seu centro est√° firme e est√°vel."
   - "Muito bem! Os ombros e quadris est√£o alinhados perfeitamente."
   - "√ìtimo trabalho! A base est√° s√≥lida."
   - "Continue assim! O movimento est√° fluindo com harmonia."
   
2. Se a t√©cnica est√° **INCORRETA/PRECISA MELHORAR**: Corrija com compaix√£o, mas seja direto:
   - "Seu centro precisa baixar um pouco. Sinta as ra√≠zes na terra."
   - "Os cotovelos est√£o travados. Mantenha uma leve flex√£o."
   
3. Se est√° **PARCIALMENTE CORRETA**: Elogie o que est√° bom E corrija o que precisa:
   - "√ìtimo alinhamento de ombros! Agora, abaixe o centro para maior estabilidade."

4. NUNCA mencione porcentagens, n√∫meros ou graus
5. N√ÉO comente sobre identidade, apar√™ncia ou roupas ‚Äî foque APENAS na t√©cnica
6. Use descri√ß√µes qualitativas: "cotovelo dobrado", "centro alto", "base estreita"
7. D√™ feedback PR√ÅTICO e DIRETO: "Abaixe", "Alinhe", "Amplie", "Flexione"
8. Sua resposta deve ter **no m√°ximo 80 palavras** (seja conciso e objetivo como um sensei)
9. MET√ÅFORAS: Use NO M√ÅXIMO UMA met√°fora por resposta (quando apropriado). N√£o encha o texto de met√°foras. Exemplos:
   - ‚úÖ BOM: "Abaixe o centro, como ra√≠zes na terra. Amplie a base."
   - ‚ùå RUIM: "Como bambu... como √°gua... como ra√≠zes... como vento..."
   - ‚úÖ BOM: "Mantenha leve flex√£o nos cotovelos. Alinhe os ombros."
   - Seja DIRETO e PR√ÅTICO, n√£o po√©tico demais

**Formato da resposta:**
Texto direto e natural, como um sensei falando no d≈çj≈ç. Sem JSON, sem formata√ß√£o, sem n√∫meros.

**Exemplos:**

*Se BOM:*
"Excelente! Seu centro est√° firme e bem conectado ao solo. Os ombros e quadris formam uma linha harmoniosa. Continue assim, mantendo essa estabilidade."

*Se PRECISA CORRE√á√ÉO:*
"Seu centro est√° elevado. Abaixe-o, sentindo as ra√≠zes na terra. Os cotovelos est√£o travados ‚Äî mantenha uma leve flex√£o. Amplie a base para maior estabilidade."

*Se PARCIALMENTE BOM:*
"Bom alinhamento de ombros! Agora, baixe o centro para maior estabilidade. Os cotovelos precisam de uma leve flex√£o. Amplie a base."

**LEMBRE-SE: Seja DIRETO e OBJETIVO. Uma met√°fora no m√°ximo. O aluno precisa de clareza, n√£o poesia.**`;
}

// ========================================
// CHAMAR GPT-4 VISION API
// ========================================

async function callGPT4Vision(prompt, images) {
    /**
     * Chama GPT-4 Vision com uma ou m√∫ltiplas imagens
     * @param {string} prompt - O prompt de an√°lise
     * @param {string|string[]} images - Uma imagem base64 ou array de imagens
     */
    const imageArray = Array.isArray(images) ? images : [images];
    
    const messages = [
        {
            role: 'user',
            content: []
        }
    ];
    
    // Adicionar todas as imagens (se dispon√≠veis)
    imageArray.forEach((imageBase64, index) => {
        if (imageBase64) {
            messages[0].content.push({
                type: 'image_url',
                image_url: {
                    url: `data:image/jpeg;base64,${imageBase64}`,
                    detail: 'low' // 'low' = mais barato e r√°pido, 'high' = mais detalhado
                }
            });
        }
    });
    
    // Adicionar texto do prompt
    messages[0].content.push({
        type: 'text',
        text: prompt
    });
    
    if (CONFIG.DEBUG && imageArray.length > 1) {
        console.log(`üì§ Enviando ${imageArray.length} imagens para an√°lise`);
    }
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${CONFIG.OPENAI_API_KEY}`
        },
        body: JSON.stringify({
            model: CONFIG.OPENAI_MODEL,
            messages: messages,
            max_tokens: 500,
            temperature: 0.7
        })
    });
    
    if (!response.ok) {
        const error = await response.json();
        throw new Error(`OpenAI API Error: ${error.error?.message || response.statusText}`);
    }
    
    const data = await response.json();
    const analysis = data.choices[0].message.content;
    
    if (CONFIG.DEBUG) {
        console.log('ü§ñ Resposta GPT-4:', analysis);
    }
    
    return analysis;
}

// ========================================
// EXIBIR FEEDBACK NA TELA
// ========================================

function displayFeedback(analysis, metrics) {
    feedbackText.textContent = analysis;
    
    landmarksInfo.innerHTML = `
        <h4>üìä Dados T√©cnicos:</h4>
        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 10px;">
            <div>
                <strong>Cotovelo Dir.:</strong> ${metrics.angles.rightElbow}¬∞<br>
                <strong>Cotovelo Esq.:</strong> ${metrics.angles.leftElbow}¬∞<br>
                <strong>Ombro Dir.:</strong> ${metrics.angles.rightShoulder}¬∞<br>
                <strong>Ombro Esq.:</strong> ${metrics.angles.leftShoulder}¬∞
            </div>
            <div>
                <strong>Alinhamento:</strong> ${metrics.alignments.shoulderHipAlignment.toFixed(1)}%<br>
                <strong>Centro:</strong> ${metrics.center.deviation.toFixed(1)}% desvio<br>
                <strong>Base:</strong> ${metrics.distances.footDistance.toFixed(1)}%<br>
                <strong>Postura:</strong> ${metrics.distances.postureHeight.toFixed(1)}%
            </div>
        </div>
    `;
    
    feedbackArea.classList.remove('hidden');
}

// ========================================
// GERAR √ÅUDIO COM ELEVENLABS
// ========================================

async function generateAndPlayAudio(text) {
    statusDiv.textContent = 'Gerando √°udio...';
    statusDiv.classList.remove('analyzing');
    statusDiv.classList.add('speaking');
    
    try {
        const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${CONFIG.ELEVENLABS_VOICE_ID}`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'xi-api-key': CONFIG.ELEVENLABS_API_KEY
            },
            body: JSON.stringify({
                text: text,
                model_id: 'eleven_multilingual_v2',
                voice_settings: {
                    stability: 0.5,
                    similarity_boost: 0.75
                }
            })
        });
        
        if (!response.ok) {
            throw new Error(`ElevenLabs API Error: ${response.statusText}`);
        }
        
        const audioBlob = await response.blob();
        const audioUrl = URL.createObjectURL(audioBlob);
        
        audioPlayer.src = audioUrl;
        
        // Tentar tocar o √°udio (pode ser bloqueado em mobile)
        try {
            const playPromise = audioPlayer.play();
            
            if (playPromise !== undefined) {
                await playPromise;
                
                // ‚úÖ Autoplay funcionou!
                if (CONFIG.DEBUG) {
                    console.log('üîä √Åudio gerado e reproduzindo (autoplay OK)');
                }
                
                // Ocultar bot√£o de fallback se estiver vis√≠vel
                playAudioBtn.classList.add('hidden');
                
            }
        } catch (autoplayError) {
            // ‚ùå Autoplay bloqueado (comum em mobile)
            console.warn('‚ö†Ô∏è Autoplay bloqueado pelo navegador. Mostrando bot√£o manual.', autoplayError);
            
            // Mostrar bot√£o de fallback
            playAudioBtn.classList.remove('hidden');
            
            // Configurar bot√£o para tocar o √°udio quando clicado
            playAudioBtn.onclick = async () => {
                try {
                    await audioPlayer.play();
                    playAudioBtn.classList.add('hidden');
                    
                    if (CONFIG.DEBUG) {
                        console.log('üîä √Åudio iniciado manualmente pelo usu√°rio');
                    }
                } catch (err) {
                    console.error('‚ùå Erro ao tocar √°udio manualmente:', err);
                    alert('Erro ao reproduzir √°udio. Tente novamente.');
                }
            };
            
            statusDiv.textContent = '‚ö†Ô∏è Toque no bot√£o para ouvir o Mestre';
        }
        
        // Listener para quando o √°udio terminar
        audioPlayer.onended = () => {
            statusDiv.textContent = 'Pronto para nova an√°lise';
            statusDiv.classList.remove('speaking');
            statusDiv.classList.add('detecting');
            playAudioBtn.classList.add('hidden'); // Ocultar bot√£o quando terminar
        };
        
    } catch (error) {
        console.error('‚ùå Erro ao gerar √°udio:', error);
        statusDiv.textContent = 'Erro ao gerar √°udio (feedback vis√≠vel acima)';
        statusDiv.classList.remove('speaking');
        statusDiv.classList.add('detecting');
    }
}

// ========================================
// EVENT LISTENERS
// ========================================

analyzeBtn.addEventListener('click', analyzeMovement);

// Bot√£o de trocar c√¢mera removido - fixado em c√¢mera traseira
/*
toggleCameraBtn.addEventListener('click', async () => {
    // Desabilitar bot√£o durante troca
    toggleCameraBtn.disabled = true;
    statusDiv.textContent = 'Trocando c√¢mera...';
    
    // Trocar entre c√¢mera frontal e traseira
    facingMode = facingMode === 'user' ? 'environment' : 'user';
    
    console.log(`üîÑ Trocando para: ${facingMode === 'user' ? 'frontal' : 'traseira'}`);
    
    try {
        // Parar c√¢mera atual
        if (currentStream) {
            currentStream.getTracks().forEach(track => track.stop());
        }
        
        // Parar MediaPipe temporariamente
        if (camera) {
            camera.stop();
        }
        
        // Limpar stream
        video.srcObject = null;
        currentStream = null;
        
        // Aguardar um pouco antes de reiniciar
        await new Promise(resolve => setTimeout(resolve, 500));
        
        // Solicitar nova c√¢mera com facingMode correto
        const constraints = {
            video: {
                facingMode: facingMode, // Sem 'exact' para melhor compatibilidade mobile
                width: { ideal: 1280 },
                height: { ideal: 720 }
            }
        };
        
        currentStream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = currentStream;
        
        // Aguardar v√≠deo carregar
        await new Promise(resolve => {
            video.addEventListener('loadeddata', resolve, { once: true });
        });
        
        // Reconfigurar canvas
        const containerWidth = video.parentElement.offsetWidth;
        const containerHeight = video.parentElement.offsetHeight;
        canvas.width = containerWidth;
        canvas.height = containerHeight;
        
        // Reiniciar MediaPipe Camera
        camera = new Camera(video, {
            onFrame: async () => {
                await pose.send({ image: video });
            },
            width: 1280,
            height: 720
        });
        
        camera.start();
        statusDiv.textContent = 'C√¢mera ativa - Posicione-se';
        statusDiv.classList.add('detecting');
        
        console.log(`‚úÖ C√¢mera ${facingMode === 'user' ? 'frontal' : 'traseira'} ativada`);
        
    } catch (error) {
        console.error('‚ùå Erro ao trocar c√¢mera:', error);
        
        // Se falhar com exact, tentar sem exact
        facingMode = facingMode === 'user' ? 'environment' : 'user';
        await initCamera();
    } finally {
        toggleCameraBtn.disabled = false;
    }
});
*/

